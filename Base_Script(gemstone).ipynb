{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd5bbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting category-encoders\n",
      "  Using cached category_encoders-2.5.0-py2.py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from category-encoders) (0.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from category-encoders) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from category-encoders) (1.7.3)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from category-encoders) (1.4.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from category-encoders) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from category-encoders) (1.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category-encoders) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category-encoders) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category-encoders) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category-encoders) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category-encoders) (1.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category-encoders) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.9.0->category-encoders) (3.0.4)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install category-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b060f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries -\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8525064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing -\n",
    "def preprocess(raw_data, drop_cols):\n",
    "\n",
    "    # Removing unnecessary columns -\n",
    "    raw_data.drop(columns=drop_cols, inplace=True)\n",
    "    \n",
    "    # Dropping duplicate rows -\n",
    "    raw_data.drop_duplicates(inplace=True)\n",
    "    \n",
    "    numerical_data = raw_data.select_dtypes(include='number')\n",
    "    num_cols = numerical_data.columns\n",
    "    \n",
    "    categorical_data = raw_data.select_dtypes(exclude='number')\n",
    "    cat_cols = categorical_data.columns\n",
    "    \n",
    "    # Removing outliers -\n",
    "    Q1 = raw_data[num_cols].quantile(0.25)\n",
    "    Q3 = raw_data[num_cols].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    raw_data = raw_data[~((raw_data<(Q1-1.5*IQR))|(raw_data>(Q3+1.5*IQR))).any(axis=1)]\n",
    "    \n",
    "    # Encoding the categorical variables -\n",
    "    ord_encoder = ce.OrdinalEncoder(cols=cat_cols)\n",
    "    processed_data = ord_encoder.fit_transform(raw_data)\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37b305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(processed_data, y_var, split_ratio=[]):   \n",
    "    \n",
    "    # Splitting the data into dependent & independent variables -\n",
    "    X = processed_data.drop(columns=y_var, axis=1)\n",
    "    y = processed_data[y_var].values\n",
    "    \n",
    "    # Performing train-test split -\n",
    "    train_ratio = split_ratio[0] / 100\n",
    "    validation_ratio = split_ratio[1] / 100\n",
    "    test_ratio = split_ratio[2] / 100\n",
    "    \n",
    "    X_train, x_test, y_train, y_test = train_test_split(X, y, test_size=1-train_ratio, \n",
    "                                                        shuffle=True, random_state=42)\n",
    "    \n",
    "    X_val, X_test, y_val, y_test = train_test_split(x_test, y_test, \n",
    "                                                    test_size=test_ratio/(test_ratio + validation_ratio), \n",
    "                                                    shuffle=True, random_state=42) \n",
    "    \n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    X_val = X_val.values\n",
    "    \n",
    "    return X, y, X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f6f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model_obj, X_train, X_test, X_val,  y_train, y_test, y_val):\n",
    "    \n",
    "    model_obj.fit(X_train, y_train)\n",
    "    y_pred_test = model_obj.predict(X_test)\n",
    "    y_pred_val = model_obj.predict(X_val)\n",
    "    print(\"R2 Score (Test): {:.2f}\".format(r2_score(y_test, y_pred_test)))\n",
    "    print(\"R2 Score (Validation): {:.2f}\".format(r2_score(y_val, y_pred_val)))\n",
    "    \n",
    "    return model_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d94fc76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_obj, X, y):\n",
    "    \n",
    "    kfold = KFold(n_splits=5)\n",
    "    accuracy = np.mean(cross_val_score(model_obj, X, y, cv=kfold, scoring='r2', n_jobs=-1)) \n",
    "    print(\"Cross Validation Score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15547d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_model(model_file, model_obj):\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(model_obj, f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d8edd",
   "metadata": {},
   "source": [
    "'''\n",
    "def standardizer(X_train, X_test):\n",
    "\n",
    "    # Standardizing the data -\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    X_scaled = np.concatenate([X_train_scaled, X_test_scaled], axis=0)\n",
    "\n",
    "    return X_scaled, X_train_scaled, X_test_scaled \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b87b7",
   "metadata": {},
   "source": [
    "# THANK YOU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
